{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import register_data_args, load_data\n",
    "from dgl.nn.pytorch.conv import SAGEConv\n",
    "\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass, field, asdict, make_dataclass\n",
    "from typing import List, Callable\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import utils\n",
    "import graph_model\n",
    "import graph_utils\n",
    "reload(utils)\n",
    "reload(graph_model)\n",
    "reload(graph_utils)\n",
    "\n",
    "from utils import get_metrics_dict\n",
    "from graph_utils import build_graph, get_train_val_test_masks\n",
    "from graph_model import GraphSAGE\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"/scratch/nh1724/\" #\"/scratch/mz2476/wiki/data/aligned_datasets/\"\n",
    "PATH_TO_MODELS = \"/scratch/nh1724/\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#load feature dataframes\n",
    "with open(os.path.join(PATH_TO_DATA, \"graph_df.pkl\"), \"rb\") as f:\n",
    "    wiki_graph_df = pkl.load(f)\n",
    "\n",
    "with open(os.path.join(PATH_TO_DATA, \"text_embed_en.pkl\"), \"rb\") as f:\n",
    "    wiki_feature_df = pkl.load(f)\n",
    "\n",
    "with open(os.path.join(PATH_TO_DATA, \"en_outlinks_tokens_df.pkl\"), \"rb\") as f:\n",
    "    wiki_label_df = pkl.load(f)\n",
    "    \n",
    "joined_df = wiki_feature_df.join(wiki_graph_df, lsuffix='1')\n",
    "joined_df = joined_df.join(wiki_label_df, lsuffix='2').sort_values(by='node_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID1</th>\n",
       "      <th>text_1000_embed</th>\n",
       "      <th>QID2</th>\n",
       "      <th>node_id</th>\n",
       "      <th>to_nodes</th>\n",
       "      <th>QID</th>\n",
       "      <th>title</th>\n",
       "      <th>raw_outlinks</th>\n",
       "      <th>outlinks</th>\n",
       "      <th>raw_tokens</th>\n",
       "      <th>tokens</th>\n",
       "      <th>mid_level_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q6199</td>\n",
       "      <td>[tensor(-0.0119), tensor(-0.0165), tensor(-0.0...</td>\n",
       "      <td>Q6199</td>\n",
       "      <td>0</td>\n",
       "      <td>[10810, 31108, 1477, 32954, 33284, 3969, 6429,...</td>\n",
       "      <td>Q6199</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>[[[Anti-authoritarianism|anti-authoritarian]],...</td>\n",
       "      <td>[Anti-authoritarianism, political philosophy, ...</td>\n",
       "      <td>[anarchism, is, an, anti, authoritarianism, an...</td>\n",
       "      <td>[anarchism, anti, authoritarianism, anti, auth...</td>\n",
       "      <td>[History_And_Society.History and society, Hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q38404</td>\n",
       "      <td>[tensor(-0.0052), tensor(-0.0246), tensor(-0.0...</td>\n",
       "      <td>Q38404</td>\n",
       "      <td>1</td>\n",
       "      <td>[29931, 9899, 5124, 26669, 6874, 1103, 1103, 1...</td>\n",
       "      <td>Q38404</td>\n",
       "      <td>Autism</td>\n",
       "      <td>[[[Psychiatry]], [[Interpersonal relationship|...</td>\n",
       "      <td>[Psychiatry, Interpersonal relationship, commu...</td>\n",
       "      <td>[autism, is, developmental, disorder, characte...</td>\n",
       "      <td>[autism, developmental, disorder, characterize...</td>\n",
       "      <td>[STEM.Medicine, STEM.Biology, History_And_Soci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     QID1                                    text_1000_embed    QID2  node_id  \\\n",
       "0   Q6199  [tensor(-0.0119), tensor(-0.0165), tensor(-0.0...   Q6199        0   \n",
       "1  Q38404  [tensor(-0.0052), tensor(-0.0246), tensor(-0.0...  Q38404        1   \n",
       "\n",
       "                                            to_nodes     QID      title  \\\n",
       "0  [10810, 31108, 1477, 32954, 33284, 3969, 6429,...   Q6199  Anarchism   \n",
       "1  [29931, 9899, 5124, 26669, 6874, 1103, 1103, 1...  Q38404     Autism   \n",
       "\n",
       "                                        raw_outlinks  \\\n",
       "0  [[[Anti-authoritarianism|anti-authoritarian]],...   \n",
       "1  [[[Psychiatry]], [[Interpersonal relationship|...   \n",
       "\n",
       "                                            outlinks  \\\n",
       "0  [Anti-authoritarianism, political philosophy, ...   \n",
       "1  [Psychiatry, Interpersonal relationship, commu...   \n",
       "\n",
       "                                          raw_tokens  \\\n",
       "0  [anarchism, is, an, anti, authoritarianism, an...   \n",
       "1  [autism, is, developmental, disorder, characte...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [anarchism, anti, authoritarianism, anti, auth...   \n",
       "1  [autism, developmental, disorder, characterize...   \n",
       "\n",
       "                                mid_level_categories  \n",
       "0  [History_And_Society.History and society, Hist...  \n",
       "1  [STEM.Medicine, STEM.Biology, History_And_Soci...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33823, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 s, sys: 305 ms, total: 18.1 s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "G = build_graph(joined_df, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33823, 45)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load LDA learned topic dist\n",
    "#check features\n",
    "features = pkl.load(open(PATH_TO_DATA + \"features.pkl\", \"rb\"))\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33823, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_top = pkl.load(open(PATH_TO_DATA + \"features_top.pkl\", \"rb\"))\n",
    "features_top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(joined_df.mid_level_categories)\n",
    "labels = torch.FloatTensor(labels)\n",
    "\n",
    "# Add train/val/test masks\n",
    "train_mask, val_mask, test_mask = get_train_val_test_masks(G.number_of_nodes())\n",
    "\n",
    "# Add features for all nodes\n",
    "G.ndata['node_id'] = torch.arange(G.number_of_nodes())\n",
    "embeds = np.nan_to_num(np.stack(joined_df.text_1000_embed.values), nan=0.)\n",
    "G.ndata['_text_embed'] = torch.FloatTensor(embeds)\n",
    "\n",
    "# Add features ONLY for train\n",
    "G.ndata['_topics'] = labels * train_mask[:, None].float()\n",
    "G.ndata['_empty'] = torch.zeros(G.number_of_nodes(), 0)\n",
    "\n",
    "# Add features from LDA (for all nodes)\n",
    "G.ndata['_LDA'] = torch.FloatTensor(features)\n",
    "\n",
    "# Add LDA for train only\n",
    "G.ndata['_LDA_train'] = torch.FloatTensor(features) * train_mask[:, None].float()\n",
    "\n",
    "# Add features from LDA (for all nodes): top cateogory only\n",
    "G.ndata['_LDA_top'] = torch.FloatTensor(features_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Args:\n",
    "    embedding_dim    : int = 150\n",
    "    n_hidden         : int = 150\n",
    "    n_layers         : int = 2\n",
    "    aggregator_type  : str = \"mean\" # ``mean``, ``gcn``, ``pool``, ``lstm``\n",
    "    activation       : Callable = partial(F.leaky_relu, negative_slope=0.1)\n",
    "\n",
    "    n_classes    : int = labels.shape[1]\n",
    "    num_nodes    : int = G.number_of_nodes()\n",
    "    features_dim : int = 0\n",
    "\n",
    "    lr           : float = 0.01\n",
    "    weight_decay : float = 0.\n",
    "    dropout      : float = 0.1\n",
    "    step_size    : int = 200\n",
    "    n_epochs     : int = 300\n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(graph_utils)\n",
    "\n",
    "from graph_utils import predict, train_GraphSAGE, get_gpu_memory_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.ndata[\"features\"] = G.ndata['_text_embed'][:, 0:1]\n",
    "\n",
    "# args = Args(\n",
    "#             features_dim=G.ndata[\"features\"].shape[1],\n",
    "#             embedding_dim=10,\n",
    "#             n_hidden=10,\n",
    "#             n_layers=4,\n",
    "#             aggregator_type=\"gcn\",\n",
    "#             lr=0.001,\n",
    "#         )\n",
    "\n",
    "# model = GraphSAGE(**asdict(args))\n",
    "\n",
    "\n",
    "# model.to(device)\n",
    "# labels = labels.to(device)\n",
    "# G.ndata[\"features\"] = G.ndata[\"features\"].to(device)\n",
    "# G.ndata[\"node_id\"] = G.ndata[\"node_id\"].to(device)\n",
    "# train_mask = train_mask.to(device)\n",
    "# val_mask = val_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_features = [\n",
    "#     ['_empty'],\n",
    "#     ['_topics'],\n",
    "#     ['_text_embed'],\n",
    "#     ['_topics', '_text_embed']\n",
    "# ]\n",
    "# list_emb_dim = [100, 200, 300]\n",
    "# list_n_hidden = [50, 100, 150]\n",
    "# list_n_layers = [1, 2, 3]\n",
    "# list_aggregator = [\n",
    "# #     \"mean\",\n",
    "# #     \"gcn\", \n",
    "# #     \"pool\",\n",
    "#     \"lstm\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33823, 345])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_names = ['_topics', '_text_embed']\n",
    "G.ndata[\"features\"] = torch.cat([G.ndata[name] for name in features_names], dim=1)\n",
    "G.ndata[\"features\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_features = [\n",
    "    ['_LDA_top']\n",
    "#    ['_empty'],\n",
    "#    ['_LDA']\n",
    "#     ['_topics'],\n",
    "#     ['_text_embed'],\n",
    "#     ['_topics', '_text_embed']\n",
    "]\n",
    "list_emb_dim = [200]\n",
    "list_n_hidden = [200]\n",
    "list_n_layers = [1]\n",
    "list_aggregator = [\n",
    "#     \"mean\",\n",
    "    \"gcn\", \n",
    "#     \"pool\",\n",
    "#     \"lstm\"\n",
    "]\n",
    "\n",
    "def run_grid_search(G, labels, train_mask, val_mask, device, FNAME):\n",
    "    metrics_list = []\n",
    "\n",
    "    for features_names, embedding_dim, n_hidden, n_layers, aggregator_type\\\n",
    "        in product(list_features, list_emb_dim, list_n_hidden, list_n_layers, list_aggregator):\n",
    "\n",
    "        print(50*\"--\")\n",
    "        print(\"features_names, embedding_dim, n_hidden, n_layers, aggregator_type:\\n\", \n",
    "              features_names, embedding_dim, n_hidden, n_layers, aggregator_type)\n",
    "\n",
    "        if len(features_names) > 1:\n",
    "            G.ndata[\"features\"] = torch.cat([G.ndata[name] for name in features_names], dim=1)\n",
    "        elif len(features_names) == 1:\n",
    "            G.ndata[\"features\"] = G.ndata[features_names[0]]\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        args = Args(\n",
    "            features_dim=G.ndata[\"features\"].shape[1],\n",
    "            embedding_dim=embedding_dim,\n",
    "            n_hidden=n_hidden,\n",
    "            n_layers=n_layers,\n",
    "            aggregator_type=aggregator_type,\n",
    "            n_epochs=400,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "\n",
    "        model = GraphSAGE(**asdict(args))\n",
    "\n",
    "\n",
    "        model.to(device)\n",
    "        labels = labels.to(device)\n",
    "        G.ndata[\"features\"] = G.ndata[\"features\"].to(device)\n",
    "        G.ndata[\"node_id\"] = G.ndata[\"node_id\"].to(device)\n",
    "        train_mask = train_mask.to(device)\n",
    "        val_mask = val_mask.to(device)\n",
    "\n",
    "        use_loss_reweighting = False\n",
    "        pos_weights = 1 / labels[train_mask].mean(axis=0) if use_loss_reweighting else None\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "        model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.Adam(model_parameters, lr=args.lr, weight_decay=args.weight_decay)\n",
    "        exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=0.01)\n",
    "\n",
    "        metrics = train_GraphSAGE(model, criterion, optimizer, exp_lr_scheduler, \n",
    "                        device, \"test\", asdict(args), args.n_epochs,\n",
    "                        G, labels, train_mask, val_mask)\n",
    "        metrics_list.append(metrics)\n",
    "        torch.save(metrics_list, PATH_TO_MODELS + FNAME)\n",
    "        \n",
    "        \n",
    "        print(get_gpu_memory_map())\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "  \n",
    "    return metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "features_names, embedding_dim, n_hidden, n_layers, aggregator_type:\n",
      " ['_empty'] 200 200 1 gcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nh1724/.conda/envs/lda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.05277 | Validation f1_micro 0.637\n",
      "Epoch 199 | Train Loss: 0.03009 | Validation f1_micro 0.611\n",
      "Epoch 299 | Train Loss: 0.02974 | Validation f1_micro 0.61\n",
      "Epoch 399 | Train Loss: 0.02962 | Validation f1_micro 0.608\n",
      "\n",
      "Training complete in 0m 40s\n",
      "Best val f1_micro: 0.6430 \n",
      "\n",
      "{0: 1113}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "features_names, embedding_dim, n_hidden, n_layers, aggregator_type:\n",
      " ['_empty'] 200 200 2 gcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nh1724/.conda/envs/lda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.06978 | Validation f1_micro 0.617\n",
      "Epoch 199 | Train Loss: 0.04889 | Validation f1_micro 0.621\n",
      "Epoch 299 | Train Loss: 0.04824 | Validation f1_micro 0.62\n",
      "Epoch 399 | Train Loss: 0.04815 | Validation f1_micro 0.625\n",
      "\n",
      "Training complete in 0m 43s\n",
      "Best val f1_micro: 0.6330 \n",
      "\n",
      "{0: 1239}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "features_names, embedding_dim, n_hidden, n_layers, aggregator_type:\n",
      " ['_LDA'] 200 200 1 gcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nh1724/.conda/envs/lda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.0542 | Validation f1_micro 0.644\n",
      "Epoch 199 | Train Loss: 0.03088 | Validation f1_micro 0.616\n",
      "Epoch 299 | Train Loss: 0.03068 | Validation f1_micro 0.618\n",
      "Epoch 399 | Train Loss: 0.03031 | Validation f1_micro 0.614\n",
      "\n",
      "Training complete in 0m 42s\n",
      "Best val f1_micro: 0.6470 \n",
      "\n",
      "{0: 1183}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "features_names, embedding_dim, n_hidden, n_layers, aggregator_type:\n",
      " ['_LDA'] 200 200 2 gcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nh1724/.conda/envs/lda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.06927 | Validation f1_micro 0.624\n",
      "Epoch 199 | Train Loss: 0.04849 | Validation f1_micro 0.627\n",
      "Epoch 299 | Train Loss: 0.04788 | Validation f1_micro 0.621\n",
      "Epoch 399 | Train Loss: 0.04764 | Validation f1_micro 0.624\n",
      "\n",
      "Training complete in 0m 42s\n",
      "Best val f1_micro: 0.6330 \n",
      "\n",
      "{0: 1287}\n"
     ]
    }
   ],
   "source": [
    "#add LDA as feature: f1-score 64.7%\n",
    "#try 1 or 2 hidden layers\n",
    "d = run_grid_search(G, labels, train_mask, val_mask, device, \"results.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "features_names, embedding_dim, n_hidden, n_layers, aggregator_type:\n",
      " ['_LDA_top'] 200 200 1 gcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nh1724/.conda/envs/lda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.05297 | Validation f1_micro 0.641\n",
      "Epoch 199 | Train Loss: 0.03025 | Validation f1_micro 0.61\n",
      "Epoch 299 | Train Loss: 0.02991 | Validation f1_micro 0.615\n",
      "Epoch 399 | Train Loss: 0.02968 | Validation f1_micro 0.61\n",
      "\n",
      "Training complete in 0m 41s\n",
      "Best val f1_micro: 0.6460 \n",
      "\n",
      "{0: 1165}\n"
     ]
    }
   ],
   "source": [
    "#add LDA and topics as train feature: f1-score \n",
    "d = run_grid_search(G, labels, train_mask, val_mask, device, \"results_lda_top.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_names, embedding_dim, n_hidden, n_layers, aggregator_type:\n",
    "#  ['_empty'] 100 150 2 mean\n",
    "# Epoch 99 | Train Loss: 0.05154 | Validation f1_micro 0.601\n",
    "# Epoch 199 | Train Loss: 0.008532 | Validation f1_micro 0.598\n",
    "# Epoch 299 | Train Loss: 0.008263 | Validation f1_micro 0.594\n",
    "# Epoch 399 | Train Loss: 0.008067 | Validation f1_micro 0.592\n",
    "# Training complete in 0m 43s\n",
    "# Best val f1_micro: 0.6050 \n",
    "\n",
    "# features_names, embedding_dim, n_hidden, n_layers, aggregator_type:\n",
    "#  ['_empty'] 100 150 1 gcn\n",
    "# Epoch 99 | Train Loss: 0.06535 | Validation f1_micro 0.626\n",
    "# Epoch 199 | Train Loss: 0.03704 | Validation f1_micro 0.624\n",
    "# Epoch 299 | Train Loss: 0.03665 | Validation f1_micro 0.625\n",
    "# Epoch 399 | Train Loss: 0.03643 | Validation f1_micro 0.624\n",
    "\n",
    "# Training complete in 0m 24s\n",
    "# Best val f1_micro: 0.6410 \n",
    "\n",
    "\n",
    "# features_names, embedding_dim, n_hidden, n_layers, aggregator_type:\n",
    "#  ['_empty'] 300 150 1 gcn\n",
    "# Epoch 99 | Train Loss: 0.0509 | Validation f1_micro 0.643\n",
    "# Epoch 199 | Train Loss: 0.02739 | Validation f1_micro 0.606\n",
    "# Epoch 299 | Train Loss: 0.02689 | Validation f1_micro 0.603\n",
    "# Epoch 399 | Train Loss: 0.02658 | Validation f1_micro 0.604\n",
    "\n",
    "# Training complete in 0m 31s\n",
    "# Best val f1_micro: 0.6430 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH_TO_MODELS + \"test\"):\n",
    "    os.mkdir(PATH_TO_MODELS + \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-be62c16cd77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m d = train_GraphSAGE(model, criterion, optimizer, exp_lr_scheduler, \n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     G, train_mask, val_mask)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "d = train_GraphSAGE(model, criterion, optimizer, exp_lr_scheduler, \n",
    "                    device, \"test\", asdict(args), args.n_epochs,\n",
    "                    G, train_mask, val_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# def get_gpu_memory_map():\n",
    "#     \"\"\"Get the current gpu usage.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     usage: dict\n",
    "#         Keys are device ids as integers.\n",
    "#         Values are memory usage as integers in MB.\n",
    "#     \"\"\"\n",
    "#     result = subprocess.check_output(\n",
    "#         [\n",
    "#             'nvidia-smi', '--query-gpu=memory.used',\n",
    "#             '--format=csv,nounits,noheader'\n",
    "#         ], encoding='utf-8')\n",
    "#     # Convert lines into a dictionary\n",
    "#     gpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
    "#     gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
    "#     return gpu_memory_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pretty_size(size):\n",
    "# \t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "# \tassert(isinstance(size, torch.Size))\n",
    "# \treturn \" × \".join(map(str, size))\n",
    "\n",
    "# def dump_tensors(gpu_only=True):\n",
    "# \t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "# \timport gc\n",
    "# \ttotal_size = 0\n",
    "# \tfor obj in gc.get_objects():\n",
    "# \t\ttry:\n",
    "# \t\t\tif torch.is_tensor(obj):\n",
    "# \t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "# \t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "# \t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "# \t\t\t\t\ttotal_size += obj.numel()\n",
    "# \t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "# \t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "# \t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "# \t\t\t\t\ttotal_size += obj.data.numel()\n",
    "# \t\texcept Exception as e:\n",
    "# \t\t\tpass        \n",
    "# \tprint(\"Total size:\", total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'state_dict': model.state_dict(),\n",
    "#     'options': options,\n",
    "#         }, f'{PATH_TO_MODELS}/node_id.pt')\n",
    "# print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_pretrained = True\n",
    "\n",
    "# if load_pretrained:\n",
    "#     if device == 'cuda':\n",
    "#         model_pt = torch.load(f'{PATH_TO_MODELS}/node_id_topics.pt')\n",
    "#     else:\n",
    "#         model_pt = torch.load(f'{PATH_TO_MODELS}/node_id_topics.pt', map_location=torch.device('cpu'))\n",
    "#     options = model_pt['options']\n",
    "    \n",
    "#     model = GraphSAGE(**options)\n",
    "#     model.load_state_dict(model_pt['state_dict'])\n",
    "#     model.to(device)\n",
    "\n",
    "# y_pred = (torch.exp(model(G)) > threshold).float()\n",
    "# get_metrics_dict(labels[val_mask].cpu(), y_pred[val_mask].cpu())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lda",
   "language": "python",
   "name": "lda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
