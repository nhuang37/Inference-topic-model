{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import nltk\n",
    "import json\n",
    "import io\n",
    "import gzip\n",
    "import torch\n",
    "import string\n",
    "import random\n",
    "#import jsonlines\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from functools import partial\n",
    "#import mwparserfromhell\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, RandomSampler, SequentialSampler, DataLoader\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import guidedlda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.25.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"/scratch/nh1724/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model_eta.pkl              results_lda_top.pth\r\n",
      "base_model_guidedlda_all.pkl    results.pth\r\n",
      "base_model_guidedlda.pkl        run-jupyter.sbatch\r\n",
      "base_model.pkl                  slurm-6130271.out\r\n",
      "en_outlinks_tokens_df.pkl       \u001b[0m\u001b[38;5;27msquad\u001b[0m/\r\n",
      "en_tokens_lem_stem_df.pkl       \u001b[48;5;10;38;5;21msquad-QA-char\u001b[0m/\r\n",
      "features.pkl                    \u001b[38;5;27mtest\u001b[0m/\r\n",
      "graph_df.pkl                    text_embed_en.pkl\r\n",
      "inference_project_teresa.ipynb  \u001b[38;5;34mwikitext_tokenized_text_sections_outlinks_en.p\u001b[0m*\r\n",
      "\u001b[38;5;27mInference-topic-model\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls $PATH_TO_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib.util\n",
    "\n",
    "# def module_from_file(module_name, file_path):\n",
    "#     spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "#     module = importlib.util.module_from_spec(spec)\n",
    "#     spec.loader.exec_module(module)\n",
    "#     return module\n",
    "\n",
    "# my_lib = module_from_file(\"my_lib\", PATH_TO_FOLDER + \"my_lib.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_df_links = pkl.load(open(PATH_TO_DATA + \"en_links_df.pkl\", \"rb\"))\n",
    "# wiki_df_tokens = pkl.load(open(PATH_TO_DATA + \"wikitext_en_tokenized.p\", \"rb\"))\n",
    "\n",
    "# assert (wiki_df_tokens.QID != wiki_df_links.QID).sum() == 0, \"Ids do not match!\"\n",
    "\n",
    "# wiki_df_links.columns\n",
    "\n",
    "# wiki_df_links[\"raw_tokens\"] = wiki_df_tokens[\"raw_tokens\"]\n",
    "# wiki_df_links[\"tokens\"] = wiki_df_tokens[\"tokens\"]\n",
    "# wiki_df_links.rename(columns={\"links\": \"raw_outlinks\", \"links_cleaned\": \"outlinks\"}, inplace=True)\n",
    "# wiki_df = wiki_df_links[[\"QID\", \"title\", \"raw_outlinks\", \"outlinks\", \"raw_tokens\", \"tokens\", \"mid_level_categories\"]]\n",
    "\n",
    "# pkl.dump(wiki_df, open(PATH_TO_DATA + \"en_outlinks_tokens_df.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = pkl.load(open(PATH_TO_DATA + \"wikitext_tokenized_text_sections_outlinks_en.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/nh1724/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(57)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(list_of_tokens):\n",
    "    output = []\n",
    "    for token in list_of_tokens:\n",
    "        output.append(stemmer.stem(lemmatizer.lemmatize(token, pos='v')))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'do', 'do', 'procrastin', 'wolv', 'cat']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "lemmatize_stemming(\"I did doing procrastination wolves cats\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del wiki_df[\"raw_tokens\"]\n",
    "wiki_df.tokens = wiki_df.tokens.apply(lemmatize_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>mid_level_categories</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sections_tokens</th>\n",
       "      <th>raw_outlinks</th>\n",
       "      <th>outlinks</th>\n",
       "      <th>tokens_lem_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q6199</td>\n",
       "      <td>[History_And_Society.History and society, Hist...</td>\n",
       "      <td>[anarch, anti, authoritarian, anti, authoritar...</td>\n",
       "      <td>[etymology, terminology, definition, history, ...</td>\n",
       "      <td>[[[Anti-authoritarianism|anti-authoritarian]],...</td>\n",
       "      <td>[Anti-authoritarianism, political philosophy, ...</td>\n",
       "      <td>[anarch, anti, authoritarian, anti, authoritar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q38404</td>\n",
       "      <td>[STEM.Medicine, STEM.Biology, History_And_Soci...</td>\n",
       "      <td>[autism, development, disord, character, diffi...</td>\n",
       "      <td>[characteristics, social, development, communi...</td>\n",
       "      <td>[[[Psychiatry]], [[Interpersonal relationship|...</td>\n",
       "      <td>[Psychiatry, Interpersonal relationship, commu...</td>\n",
       "      <td>[autism, development, disord, character, diffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q101038</td>\n",
       "      <td>[STEM.Physics, STEM.Space, History_And_Society...</td>\n",
       "      <td>[sunlight, relat, various, surfac, condit, alb...</td>\n",
       "      <td>[terrestrial, albedo, white, sky, black, sky, ...</td>\n",
       "      <td>[[[File:Albedo-e hg.svg|thumb|upright=1.3|The ...</td>\n",
       "      <td>[File:Albedo-e hg.svg, diffuse reflection, sun...</td>\n",
       "      <td>[sunlight, relat, various, surfac, condit, alb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q173</td>\n",
       "      <td>[Geography.Americas]</td>\n",
       "      <td>[alabama, alabama, nicknam, northern, flicker,...</td>\n",
       "      <td>[etymology, history, pre, european, settlement...</td>\n",
       "      <td>[[[Coat of arms of Alabama|Coat of arms]], [[N...</td>\n",
       "      <td>[Coat of arms of Alabama, Northern flicker, Di...</td>\n",
       "      <td>[alabama, alabama, nicknam, northern, flicker,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q41746</td>\n",
       "      <td>[Culture.People, Geography.Europe, History_And...</td>\n",
       "      <td>[date, three, zero, zero, bc, achill, kill, et...</td>\n",
       "      <td>[etymology, birth, early, years, names, hidden...</td>\n",
       "      <td>[[[File:Achilles fighting against Memnon Leide...</td>\n",
       "      <td>[File:Achilles fighting against Memnon Leiden ...</td>\n",
       "      <td>[date, three, zero, zero, bc, achill, kill, et...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       QID                               mid_level_categories  \\\n",
       "0    Q6199  [History_And_Society.History and society, Hist...   \n",
       "1   Q38404  [STEM.Medicine, STEM.Biology, History_And_Soci...   \n",
       "2  Q101038  [STEM.Physics, STEM.Space, History_And_Society...   \n",
       "3     Q173                               [Geography.Americas]   \n",
       "4   Q41746  [Culture.People, Geography.Europe, History_And...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [anarch, anti, authoritarian, anti, authoritar...   \n",
       "1  [autism, development, disord, character, diffi...   \n",
       "2  [sunlight, relat, various, surfac, condit, alb...   \n",
       "3  [alabama, alabama, nicknam, northern, flicker,...   \n",
       "4  [date, three, zero, zero, bc, achill, kill, et...   \n",
       "\n",
       "                                     sections_tokens  \\\n",
       "0  [etymology, terminology, definition, history, ...   \n",
       "1  [characteristics, social, development, communi...   \n",
       "2  [terrestrial, albedo, white, sky, black, sky, ...   \n",
       "3  [etymology, history, pre, european, settlement...   \n",
       "4  [etymology, birth, early, years, names, hidden...   \n",
       "\n",
       "                                        raw_outlinks  \\\n",
       "0  [[[Anti-authoritarianism|anti-authoritarian]],...   \n",
       "1  [[[Psychiatry]], [[Interpersonal relationship|...   \n",
       "2  [[[File:Albedo-e hg.svg|thumb|upright=1.3|The ...   \n",
       "3  [[[Coat of arms of Alabama|Coat of arms]], [[N...   \n",
       "4  [[[File:Achilles fighting against Memnon Leide...   \n",
       "\n",
       "                                            outlinks  \\\n",
       "0  [Anti-authoritarianism, political philosophy, ...   \n",
       "1  [Psychiatry, Interpersonal relationship, commu...   \n",
       "2  [File:Albedo-e hg.svg, diffuse reflection, sun...   \n",
       "3  [Coat of arms of Alabama, Northern flicker, Di...   \n",
       "4  [File:Achilles fighting against Memnon Leiden ...   \n",
       "\n",
       "                                     tokens_lem_stem  \n",
       "0  [anarch, anti, authoritarian, anti, authoritar...  \n",
       "1  [autism, development, disord, character, diffi...  \n",
       "2  [sunlight, relat, various, surfac, condit, alb...  \n",
       "3  [alabama, alabama, nicknam, northern, flicker,...  \n",
       "4  [date, three, zero, zero, bc, achill, kill, et...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df[\"tokens_lem_stem\"] = wiki_df[\"tokens\"]\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl.dump(wiki_df[[\"QID\", \"tokens_lem_stem\"]], open(PATH_TO_DATA + \"en_tokens_lem_stem_df.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 45, \n",
      "\n",
      "['Culture.Architecture' 'Culture.Arts' 'Culture.Broadcasting'\n",
      " 'Culture.Crafts and hobbies' 'Culture.Entertainment'\n",
      " 'Culture.Food and drink' 'Culture.Games and toys'\n",
      " 'Culture.Internet culture' 'Culture.Language and literature'\n",
      " 'Culture.Media' 'Culture.Music' 'Culture.People'\n",
      " 'Culture.Performing arts' 'Culture.Philosophy and religion'\n",
      " 'Culture.Sports' 'Culture.Visual arts' 'Geography.Africa'\n",
      " 'Geography.Americas' 'Geography.Antarctica' 'Geography.Asia'\n",
      " 'Geography.Bodies of water' 'Geography.Europe' 'Geography.Landforms'\n",
      " 'Geography.Maps' 'Geography.Oceania' 'Geography.Parks'\n",
      " 'History_And_Society.Business and economics'\n",
      " 'History_And_Society.Education' 'History_And_Society.History and society'\n",
      " 'History_And_Society.Military and warfare'\n",
      " 'History_And_Society.Politics and government'\n",
      " 'History_And_Society.Transportation' 'STEM.Biology' 'STEM.Chemistry'\n",
      " 'STEM.Engineering' 'STEM.Geosciences' 'STEM.Information science'\n",
      " 'STEM.Mathematics' 'STEM.Medicine' 'STEM.Meteorology' 'STEM.Physics'\n",
      " 'STEM.Science' 'STEM.Space' 'STEM.Technology' 'STEM.Time']\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(wiki_df.mid_level_categories)\n",
    "print(f\"Number of categories: {len(mlb.classes_)}, \\n\\n{mlb.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['History_And_Society.Business and economics',\n",
       "       'History_And_Society.Education',\n",
       "       'History_And_Society.History and society',\n",
       "       'History_And_Society.Military and warfare',\n",
       "       'History_And_Society.Politics and government',\n",
       "       'History_And_Society.Transportation'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_[26:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(wiki_df, y, test_size=0.1, random_state=42) #all train, output features\n",
    "#X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to output features, use full set for X, y\n",
    "X_train = wiki_df\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute prior eta based on a subset of whole corpus\n",
    "def init_eta(y, bow_corpus, dictionary, num_examples=1000):\n",
    "    '''\n",
    "    y: MultiLabelBinarizer array, (num_doc, num_topic)\n",
    "    bow_corpus: bag of word corpus\n",
    "    dictionary: word vocab\n",
    "    num_examples: restrict on a smaller subset as initialization\n",
    "    '''\n",
    "    eta = np.zeros(y.T.shape)\n",
    "    y = y.astype(int) #ensure integer type\n",
    "    for i in range(num_examples):\n",
    "        key_idx = np.array(list(dict(bow_corpus[i]).keys()))\n",
    "        counts = np.array(list(dict(bow_corpus[i]).values()))\n",
    "        key_idx = key_idx.astype(int) #ensure integer type\n",
    "        eta[np.ix_(y[i]==1,key_idx)] += counts\n",
    "    return eta/np.sum(eta) #normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(X_train.tokens)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5,keep_n=y_train.shape[0]) #keep same shape as num of examples to initialize the prior (can improve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in X_train.tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33823, 33823)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_corpus), len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33823, 45)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta0 = init_eta(y_train, bow_corpus,dictionary, num_examples=5000) #use small subset to guess seeded words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 33823)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## guidedLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create seeded topic for GuidedLDA (list of list)\n",
    "topic_words = []\n",
    "n_top_words=10\n",
    "for i in range(45): #45 topics\n",
    "    topic_words_i = [dictionary[idx] for idx in np.array(dictionary)[np.argsort(eta0[i])][:-(n_top_words+1):-1]]\n",
    "    topic_words.append(topic_words_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culture.Architecture</th>\n",
       "      <th>Culture.Arts</th>\n",
       "      <th>Culture.Broadcasting</th>\n",
       "      <th>Culture.Crafts and hobbies</th>\n",
       "      <th>Culture.Entertainment</th>\n",
       "      <th>Culture.Food and drink</th>\n",
       "      <th>Culture.Games and toys</th>\n",
       "      <th>Culture.Internet culture</th>\n",
       "      <th>Culture.Language and literature</th>\n",
       "      <th>Culture.Media</th>\n",
       "      <th>...</th>\n",
       "      <th>STEM.Geosciences</th>\n",
       "      <th>STEM.Information science</th>\n",
       "      <th>STEM.Mathematics</th>\n",
       "      <th>STEM.Medicine</th>\n",
       "      <th>STEM.Meteorology</th>\n",
       "      <th>STEM.Physics</th>\n",
       "      <th>STEM.Science</th>\n",
       "      <th>STEM.Space</th>\n",
       "      <th>STEM.Technology</th>\n",
       "      <th>STEM.Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>build</td>\n",
       "      <td>art</td>\n",
       "      <td>televis</td>\n",
       "      <td>card</td>\n",
       "      <td>film</td>\n",
       "      <td>food</td>\n",
       "      <td>game</td>\n",
       "      <td>game</td>\n",
       "      <td>languag</td>\n",
       "      <td>music</td>\n",
       "      <td>...</td>\n",
       "      <td>island</td>\n",
       "      <td>librari</td>\n",
       "      <td>distribut</td>\n",
       "      <td>cell</td>\n",
       "      <td>ice</td>\n",
       "      <td>energi</td>\n",
       "      <td>system</td>\n",
       "      <td>star</td>\n",
       "      <td>system</td>\n",
       "      <td>ndash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hous</td>\n",
       "      <td>jpg</td>\n",
       "      <td>seri</td>\n",
       "      <td>bank</td>\n",
       "      <td>seri</td>\n",
       "      <td>water</td>\n",
       "      <td>player</td>\n",
       "      <td>internet</td>\n",
       "      <td>write</td>\n",
       "      <td>media</td>\n",
       "      <td>...</td>\n",
       "      <td>earth</td>\n",
       "      <td>univers</td>\n",
       "      <td>mean</td>\n",
       "      <td>human</td>\n",
       "      <td>temperatur</td>\n",
       "      <td>physic</td>\n",
       "      <td>theori</td>\n",
       "      <td>orbit</td>\n",
       "      <td>comput</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>design</td>\n",
       "      <td>file</td>\n",
       "      <td>show</td>\n",
       "      <td>debit</td>\n",
       "      <td>charact</td>\n",
       "      <td>product</td>\n",
       "      <td>chess</td>\n",
       "      <td>user</td>\n",
       "      <td>word</td>\n",
       "      <td>televis</td>\n",
       "      <td>...</td>\n",
       "      <td>nbsp</td>\n",
       "      <td>leibniz</td>\n",
       "      <td>statist</td>\n",
       "      <td>effect</td>\n",
       "      <td>earth</td>\n",
       "      <td>theori</td>\n",
       "      <td>nbsp</td>\n",
       "      <td>earth</td>\n",
       "      <td>engin</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>centuri</td>\n",
       "      <td>museum</td>\n",
       "      <td>film</td>\n",
       "      <td>stamp</td>\n",
       "      <td>anim</td>\n",
       "      <td>produc</td>\n",
       "      <td>play</td>\n",
       "      <td>blog</td>\n",
       "      <td>book</td>\n",
       "      <td>film</td>\n",
       "      <td>...</td>\n",
       "      <td>water</td>\n",
       "      <td>copyright</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>diseas</td>\n",
       "      <td>snow</td>\n",
       "      <td>nbsp</td>\n",
       "      <td>scienc</td>\n",
       "      <td>space</td>\n",
       "      <td>oper</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>art</td>\n",
       "      <td>centuri</td>\n",
       "      <td>season</td>\n",
       "      <td>system</td>\n",
       "      <td>comic</td>\n",
       "      <td>plant</td>\n",
       "      <td>card</td>\n",
       "      <td>web</td>\n",
       "      <td>english</td>\n",
       "      <td>news</td>\n",
       "      <td>...</td>\n",
       "      <td>rock</td>\n",
       "      <td>carnegi</td>\n",
       "      <td>data</td>\n",
       "      <td>studi</td>\n",
       "      <td>satellit</td>\n",
       "      <td>electron</td>\n",
       "      <td>centuri</td>\n",
       "      <td>system</td>\n",
       "      <td>program</td>\n",
       "      <td>player</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jpg</td>\n",
       "      <td>sculptur</td>\n",
       "      <td>broadcast</td>\n",
       "      <td>currenc</td>\n",
       "      <td>show</td>\n",
       "      <td>process</td>\n",
       "      <td>franklin</td>\n",
       "      <td>search</td>\n",
       "      <td>publish</td>\n",
       "      <td>game</td>\n",
       "      <td>...</td>\n",
       "      <td>miner</td>\n",
       "      <td>book</td>\n",
       "      <td>frac</td>\n",
       "      <td>system</td>\n",
       "      <td>atmospher</td>\n",
       "      <td>particl</td>\n",
       "      <td>color</td>\n",
       "      <td>nbsp</td>\n",
       "      <td>design</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>file</td>\n",
       "      <td>bc</td>\n",
       "      <td>tv</td>\n",
       "      <td>knot</td>\n",
       "      <td>award</td>\n",
       "      <td>milk</td>\n",
       "      <td>film</td>\n",
       "      <td>network</td>\n",
       "      <td>film</td>\n",
       "      <td>public</td>\n",
       "      <td>...</td>\n",
       "      <td>geolog</td>\n",
       "      <td>columbia</td>\n",
       "      <td>sampl</td>\n",
       "      <td>caus</td>\n",
       "      <td>orbit</td>\n",
       "      <td>light</td>\n",
       "      <td>comput</td>\n",
       "      <td>observ</td>\n",
       "      <td>languag</td>\n",
       "      <td>actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>palac</td>\n",
       "      <td>collect</td>\n",
       "      <td>radio</td>\n",
       "      <td>reserv</td>\n",
       "      <td>releas</td>\n",
       "      <td>acid</td>\n",
       "      <td>video</td>\n",
       "      <td>video</td>\n",
       "      <td>centuri</td>\n",
       "      <td>blue</td>\n",
       "      <td>...</td>\n",
       "      <td>carbon</td>\n",
       "      <td>public</td>\n",
       "      <td>probabl</td>\n",
       "      <td>medic</td>\n",
       "      <td>nbsp</td>\n",
       "      <td>system</td>\n",
       "      <td>univers</td>\n",
       "      <td>sun</td>\n",
       "      <td>data</td>\n",
       "      <td>footbal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>citi</td>\n",
       "      <td>british</td>\n",
       "      <td>big</td>\n",
       "      <td>feder</td>\n",
       "      <td>televis</td>\n",
       "      <td>drink</td>\n",
       "      <td>hand</td>\n",
       "      <td>googl</td>\n",
       "      <td>univers</td>\n",
       "      <td>broadcast</td>\n",
       "      <td>...</td>\n",
       "      <td>larg</td>\n",
       "      <td>dictionari</td>\n",
       "      <td>popul</td>\n",
       "      <td>organ</td>\n",
       "      <td>weather</td>\n",
       "      <td>forc</td>\n",
       "      <td>human</td>\n",
       "      <td>planet</td>\n",
       "      <td>power</td>\n",
       "      <td>singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>architectur</td>\n",
       "      <td>de</td>\n",
       "      <td>program</td>\n",
       "      <td>nickel</td>\n",
       "      <td>play</td>\n",
       "      <td>common</td>\n",
       "      <td>piec</td>\n",
       "      <td>irc</td>\n",
       "      <td>letter</td>\n",
       "      <td>advertis</td>\n",
       "      <td>...</td>\n",
       "      <td>metal</td>\n",
       "      <td>school</td>\n",
       "      <td>valu</td>\n",
       "      <td>psycholog</td>\n",
       "      <td>water</td>\n",
       "      <td>relat</td>\n",
       "      <td>natur</td>\n",
       "      <td>solar</td>\n",
       "      <td>nbsp</td>\n",
       "      <td>calendar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Culture.Architecture Culture.Arts Culture.Broadcasting  \\\n",
       "0                build          art              televis   \n",
       "1                 hous          jpg                 seri   \n",
       "2               design         file                 show   \n",
       "3              centuri       museum                 film   \n",
       "4                  art      centuri               season   \n",
       "5                  jpg     sculptur            broadcast   \n",
       "6                 file           bc                   tv   \n",
       "7                palac      collect                radio   \n",
       "8                 citi      british                  big   \n",
       "9          architectur           de              program   \n",
       "\n",
       "  Culture.Crafts and hobbies Culture.Entertainment Culture.Food and drink  \\\n",
       "0                       card                  film                   food   \n",
       "1                       bank                  seri                  water   \n",
       "2                      debit               charact                product   \n",
       "3                      stamp                  anim                 produc   \n",
       "4                     system                 comic                  plant   \n",
       "5                    currenc                  show                process   \n",
       "6                       knot                 award                   milk   \n",
       "7                     reserv                releas                   acid   \n",
       "8                      feder               televis                  drink   \n",
       "9                     nickel                  play                 common   \n",
       "\n",
       "  Culture.Games and toys Culture.Internet culture  \\\n",
       "0                   game                     game   \n",
       "1                 player                 internet   \n",
       "2                  chess                     user   \n",
       "3                   play                     blog   \n",
       "4                   card                      web   \n",
       "5               franklin                   search   \n",
       "6                   film                  network   \n",
       "7                  video                    video   \n",
       "8                   hand                    googl   \n",
       "9                   piec                      irc   \n",
       "\n",
       "  Culture.Language and literature Culture.Media  ... STEM.Geosciences  \\\n",
       "0                         languag         music  ...           island   \n",
       "1                           write         media  ...            earth   \n",
       "2                            word       televis  ...             nbsp   \n",
       "3                            book          film  ...            water   \n",
       "4                         english          news  ...             rock   \n",
       "5                         publish          game  ...            miner   \n",
       "6                            film        public  ...           geolog   \n",
       "7                         centuri          blue  ...           carbon   \n",
       "8                         univers     broadcast  ...             larg   \n",
       "9                          letter      advertis  ...            metal   \n",
       "\n",
       "  STEM.Information science STEM.Mathematics STEM.Medicine STEM.Meteorology  \\\n",
       "0                  librari        distribut          cell              ice   \n",
       "1                  univers             mean         human       temperatur   \n",
       "2                  leibniz          statist        effect            earth   \n",
       "3                copyright        algorithm        diseas             snow   \n",
       "4                  carnegi             data         studi         satellit   \n",
       "5                     book             frac        system        atmospher   \n",
       "6                 columbia            sampl          caus            orbit   \n",
       "7                   public          probabl         medic             nbsp   \n",
       "8               dictionari            popul         organ          weather   \n",
       "9                   school             valu     psycholog            water   \n",
       "\n",
       "  STEM.Physics STEM.Science STEM.Space STEM.Technology   STEM.Time  \n",
       "0       energi       system       star          system       ndash  \n",
       "1       physic       theori      orbit          comput    american  \n",
       "2       theori         nbsp      earth           engin         day  \n",
       "3         nbsp       scienc      space            oper     english  \n",
       "4     electron      centuri     system         program      player  \n",
       "5      particl        color       nbsp          design  politician  \n",
       "6        light       comput     observ         languag       actor  \n",
       "7       system      univers        sun            data     footbal  \n",
       "8         forc        human     planet           power      singer  \n",
       "9        relat        natur      solar            nbsp    calendar  \n",
       "\n",
       "[10 rows x 45 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show topic and top topic_words\n",
    "df_topic = pd.DataFrame(topic_words)\n",
    "df_topic = df_topic.T\n",
    "df_topic.columns = mlb.classes_\n",
    "df_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topics = {}\n",
    "for t_id, st in enumerate(topic_words):\n",
    "    for word in st:\n",
    "        seed_topics[dictionary.token2id[word]] = t_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GuidedLDA with seed words init\n",
    "#model = guidedlda.GuidedLDA(n_topics=45, n_iter=100, random_state=7, refresh=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_map = {idx:0 for idx in range(16)}\n",
    "topic_map.update({idx:1 for idx in range(16,26,1)})\n",
    "topic_map.update({idx:2 for idx in range(26,32,1)})\n",
    "topic_map.update({idx:3 for idx in range(32,45,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GuidedLDA with only 4 broad topics\n",
    "seed_topics_top = {}\n",
    "for idx, st in enumerate(topic_words):\n",
    "    for word in st:\n",
    "        top_id = topic_map[idx]\n",
    "        seed_topics_top[dictionary.token2id[word]] = top_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1438: 1,\n",
       " 2210: 0,\n",
       " 915: 3,\n",
       " 108: 3,\n",
       " 1819: 0,\n",
       " 3252: 0,\n",
       " 2120: 0,\n",
       " 3377: 0,\n",
       " 120: 2,\n",
       " 1815: 0,\n",
       " 3328: 0,\n",
       " 3507: 0,\n",
       " 72: 1,\n",
       " 128: 0,\n",
       " 93: 0,\n",
       " 180: 1,\n",
       " 1327: 0,\n",
       " 2591: 0,\n",
       " 1281: 0,\n",
       " 2121: 1,\n",
       " 1678: 1,\n",
       " 1889: 0,\n",
       " 2744: 0,\n",
       " 6147: 0,\n",
       " 1429: 0,\n",
       " 1220: 3,\n",
       " 2935: 0,\n",
       " 1843: 0,\n",
       " 19433: 0,\n",
       " 4142: 0,\n",
       " 690: 3,\n",
       " 173: 0,\n",
       " 7184: 0,\n",
       " 5371: 0,\n",
       " 286: 0,\n",
       " 9801: 0,\n",
       " 2944: 0,\n",
       " 1804: 3,\n",
       " 6313: 0,\n",
       " 4673: 0,\n",
       " 1243: 0,\n",
       " 536: 0,\n",
       " 989: 0,\n",
       " 1751: 3,\n",
       " 1641: 2,\n",
       " 2488: 0,\n",
       " 1632: 3,\n",
       " 1217: 0,\n",
       " 2343: 0,\n",
       " 8522: 3,\n",
       " 5575: 0,\n",
       " 134: 0,\n",
       " 999: 1,\n",
       " 7620: 3,\n",
       " 5522: 0,\n",
       " 3867: 0,\n",
       " 4207: 0,\n",
       " 1017: 0,\n",
       " 3406: 0,\n",
       " 1068: 0,\n",
       " 6643: 0,\n",
       " 19859: 0,\n",
       " 4642: 0,\n",
       " 4573: 0,\n",
       " 2379: 0,\n",
       " 8132: 0,\n",
       " 14480: 0,\n",
       " 1083: 3,\n",
       " 772: 2,\n",
       " 768: 0,\n",
       " 89: 3,\n",
       " 240: 3,\n",
       " 3453: 0,\n",
       " 733: 3,\n",
       " 3944: 0,\n",
       " 1138: 0,\n",
       " 2325: 0,\n",
       " 2381: 0,\n",
       " 579: 3,\n",
       " 1432: 0,\n",
       " 1778: 0,\n",
       " 2831: 0,\n",
       " 2624: 0,\n",
       " 2520: 0,\n",
       " 1423: 0,\n",
       " 1188: 0,\n",
       " 164: 2,\n",
       " 19651: 0,\n",
       " 771: 2,\n",
       " 756: 2,\n",
       " 415: 0,\n",
       " 540: 2,\n",
       " 904: 0,\n",
       " 3362: 0,\n",
       " 4321: 0,\n",
       " 4181: 0,\n",
       " 12067: 0,\n",
       " 706: 3,\n",
       " 1580: 2,\n",
       " 2166: 0,\n",
       " 340: 3,\n",
       " 2688: 1,\n",
       " 2282: 0,\n",
       " 2135: 3,\n",
       " 5550: 0,\n",
       " 3658: 0,\n",
       " 3375: 0,\n",
       " 53: 0,\n",
       " 3909: 0,\n",
       " 5418: 1,\n",
       " 2627: 1,\n",
       " 3488: 1,\n",
       " 5582: 1,\n",
       " 31: 3,\n",
       " 321: 2,\n",
       " 1614: 1,\n",
       " 2226: 1,\n",
       " 1408: 1,\n",
       " 20496: 1,\n",
       " 1409: 1,\n",
       " 2736: 1,\n",
       " 1677: 1,\n",
       " 2245: 3,\n",
       " 2094: 1,\n",
       " 5096: 1,\n",
       " 1198: 3,\n",
       " 5382: 1,\n",
       " 6204: 1,\n",
       " 2556: 1,\n",
       " 4434: 1,\n",
       " 2388: 1,\n",
       " 1011: 1,\n",
       " 45: 1,\n",
       " 9176: 1,\n",
       " 1605: 3,\n",
       " 313: 1,\n",
       " 259: 1,\n",
       " 2362: 1,\n",
       " 6106: 1,\n",
       " 18104: 1,\n",
       " 9041: 1,\n",
       " 2905: 1,\n",
       " 1113: 1,\n",
       " 2782: 1,\n",
       " 1670: 3,\n",
       " 451: 1,\n",
       " 7719: 1,\n",
       " 7486: 1,\n",
       " 8022: 1,\n",
       " 3490: 1,\n",
       " 444: 1,\n",
       " 1965: 2,\n",
       " 220: 2,\n",
       " 434: 2,\n",
       " 718: 2,\n",
       " 221: 2,\n",
       " 635: 3,\n",
       " 1956: 2,\n",
       " 2663: 2,\n",
       " 2294: 3,\n",
       " 612: 2,\n",
       " 953: 2,\n",
       " 296: 3,\n",
       " 51: 2,\n",
       " 2342: 2,\n",
       " 796: 2,\n",
       " 1850: 2,\n",
       " 2478: 3,\n",
       " 2407: 3,\n",
       " 1174: 2,\n",
       " 621: 2,\n",
       " 229: 2,\n",
       " 2074: 3,\n",
       " 1788: 2,\n",
       " 3520: 2,\n",
       " 853: 3,\n",
       " 2634: 3,\n",
       " 498: 3,\n",
       " 10046: 3,\n",
       " 230: 3,\n",
       " 6298: 3,\n",
       " 1123: 3,\n",
       " 4300: 3,\n",
       " 2064: 3,\n",
       " 1463: 3,\n",
       " 1443: 3,\n",
       " 1505: 3,\n",
       " 1523: 3,\n",
       " 5121: 3,\n",
       " 174: 3,\n",
       " 1510: 3,\n",
       " 1594: 3,\n",
       " 1502: 3,\n",
       " 1263: 3,\n",
       " 2345: 3,\n",
       " 1539: 3,\n",
       " 400: 3,\n",
       " 13797: 3,\n",
       " 4722: 3,\n",
       " 15808: 3,\n",
       " 1959: 3,\n",
       " 2029: 3,\n",
       " 208: 3,\n",
       " 440: 3,\n",
       " 2654: 3,\n",
       " 9879: 3,\n",
       " 902: 3,\n",
       " 1532: 3,\n",
       " 1268: 3,\n",
       " 1213: 3,\n",
       " 740: 3,\n",
       " 947: 3,\n",
       " 203: 3,\n",
       " 1308: 3,\n",
       " 851: 3,\n",
       " 1115: 3,\n",
       " 1226: 3,\n",
       " 1557: 3,\n",
       " 1718: 3,\n",
       " 1692: 3,\n",
       " 1419: 3,\n",
       " 9809: 3,\n",
       " 1755: 3,\n",
       " 1192: 3,\n",
       " 1624: 3,\n",
       " 1585: 3,\n",
       " 602: 3,\n",
       " 636: 3,\n",
       " 1456: 3,\n",
       " 1969: 3,\n",
       " 471: 3,\n",
       " 2648: 3,\n",
       " 1698: 3,\n",
       " 1156: 3,\n",
       " 1709: 3,\n",
       " 1630: 3,\n",
       " 1696: 3,\n",
       " 7989: 3,\n",
       " 179: 3,\n",
       " 2468: 3,\n",
       " 3686: 3,\n",
       " 5209: 3,\n",
       " 4693: 3}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_topics_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = guidedlda.GuidedLDA(n_topics=4, n_iter=100, random_state=7, refresh=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sparse input matrix from corpus\n",
    "X = gensim.matutils.corpus2csc(bow_corpus,dtype=int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33823, 33823)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:guidedlda:n_documents: 33823\n",
      "INFO:guidedlda:vocab_size: 33823\n",
      "INFO:guidedlda:n_words: 43830236\n",
      "INFO:guidedlda:n_topics: 4\n",
      "INFO:guidedlda:n_iter: 100\n",
      "WARNING:guidedlda:all zero row in document-term matrix found\n",
      "/home/nh1724/.conda/envs/lda/lib/python3.6/site-packages/guidedlda/utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:guidedlda:<0> log likelihood: -443823432\n",
      "INFO:guidedlda:<20> log likelihood: -385607858\n",
      "INFO:guidedlda:<40> log likelihood: -384500082\n",
      "INFO:guidedlda:<60> log likelihood: -384190903\n",
      "INFO:guidedlda:<80> log likelihood: -384020308\n",
      "INFO:guidedlda:<99> log likelihood: -383894968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<guidedlda.guidedlda.GuidedLDA at 0x2b015014c0b8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, seed_topics=seed_topics_top, seed_confidence=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "pkl.dump(model, open(PATH_TO_DATA + \"base_model_guidedlda_top.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = pkl.load(open(PATH_TO_DATA + \"base_model_guidedlda_top.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 33823)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topic_word_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['ndash', 'film', 'american', 'game', 'team', 'play', 'award', 'season', 'player', 'open']\n",
      "1 ['citi', 'languag', 'india', 'area', 'district', 'region', 'popul', 'river', 'centuri', 'south']\n",
      "2 ['war', 'govern', 'polit', 'parti', 'univers', 'countri', 'law', 'elect', 'forc', 'would']\n",
      "3 ['system', 'nbsp', 'differ', 'product', 'water', 'process', 'type', 'exampl', 'common', 'effect']\n"
     ]
    }
   ],
   "source": [
    "#word topic assignment\n",
    "n_top_words = 10\n",
    "topic_word = model.topic_word_\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = [dictionary[t] for t in np.argsort(topic_dist)[:-(n_top_words+1):-1]]\n",
    "    print(str(i), topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33823, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>mid_level_categories</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sections_tokens</th>\n",
       "      <th>raw_outlinks</th>\n",
       "      <th>outlinks</th>\n",
       "      <th>tokens_lem_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q6199</td>\n",
       "      <td>[History_And_Society.History and society, Hist...</td>\n",
       "      <td>[anarch, anti, authoritarian, anti, authoritar...</td>\n",
       "      <td>[etymology, terminology, definition, history, ...</td>\n",
       "      <td>[[[Anti-authoritarianism|anti-authoritarian]],...</td>\n",
       "      <td>[Anti-authoritarianism, political philosophy, ...</td>\n",
       "      <td>[anarch, anti, authoritarian, anti, authoritar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q38404</td>\n",
       "      <td>[STEM.Medicine, STEM.Biology, History_And_Soci...</td>\n",
       "      <td>[autism, development, disord, character, diffi...</td>\n",
       "      <td>[characteristics, social, development, communi...</td>\n",
       "      <td>[[[Psychiatry]], [[Interpersonal relationship|...</td>\n",
       "      <td>[Psychiatry, Interpersonal relationship, commu...</td>\n",
       "      <td>[autism, development, disord, character, diffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q101038</td>\n",
       "      <td>[STEM.Physics, STEM.Space, History_And_Society...</td>\n",
       "      <td>[sunlight, relat, various, surfac, condit, alb...</td>\n",
       "      <td>[terrestrial, albedo, white, sky, black, sky, ...</td>\n",
       "      <td>[[[File:Albedo-e hg.svg|thumb|upright=1.3|The ...</td>\n",
       "      <td>[File:Albedo-e hg.svg, diffuse reflection, sun...</td>\n",
       "      <td>[sunlight, relat, various, surfac, condit, alb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q173</td>\n",
       "      <td>[Geography.Americas]</td>\n",
       "      <td>[alabama, alabama, nicknam, northern, flicker,...</td>\n",
       "      <td>[etymology, history, pre, european, settlement...</td>\n",
       "      <td>[[[Coat of arms of Alabama|Coat of arms]], [[N...</td>\n",
       "      <td>[Coat of arms of Alabama, Northern flicker, Di...</td>\n",
       "      <td>[alabama, alabama, nicknam, northern, flicker,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q41746</td>\n",
       "      <td>[Culture.People, Geography.Europe, History_And...</td>\n",
       "      <td>[date, three, zero, zero, bc, achill, kill, et...</td>\n",
       "      <td>[etymology, birth, early, years, names, hidden...</td>\n",
       "      <td>[[[File:Achilles fighting against Memnon Leide...</td>\n",
       "      <td>[File:Achilles fighting against Memnon Leiden ...</td>\n",
       "      <td>[date, three, zero, zero, bc, achill, kill, et...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       QID                               mid_level_categories  \\\n",
       "0    Q6199  [History_And_Society.History and society, Hist...   \n",
       "1   Q38404  [STEM.Medicine, STEM.Biology, History_And_Soci...   \n",
       "2  Q101038  [STEM.Physics, STEM.Space, History_And_Society...   \n",
       "3     Q173                               [Geography.Americas]   \n",
       "4   Q41746  [Culture.People, Geography.Europe, History_And...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [anarch, anti, authoritarian, anti, authoritar...   \n",
       "1  [autism, development, disord, character, diffi...   \n",
       "2  [sunlight, relat, various, surfac, condit, alb...   \n",
       "3  [alabama, alabama, nicknam, northern, flicker,...   \n",
       "4  [date, three, zero, zero, bc, achill, kill, et...   \n",
       "\n",
       "                                     sections_tokens  \\\n",
       "0  [etymology, terminology, definition, history, ...   \n",
       "1  [characteristics, social, development, communi...   \n",
       "2  [terrestrial, albedo, white, sky, black, sky, ...   \n",
       "3  [etymology, history, pre, european, settlement...   \n",
       "4  [etymology, birth, early, years, names, hidden...   \n",
       "\n",
       "                                        raw_outlinks  \\\n",
       "0  [[[Anti-authoritarianism|anti-authoritarian]],...   \n",
       "1  [[[Psychiatry]], [[Interpersonal relationship|...   \n",
       "2  [[[File:Albedo-e hg.svg|thumb|upright=1.3|The ...   \n",
       "3  [[[Coat of arms of Alabama|Coat of arms]], [[N...   \n",
       "4  [[[File:Achilles fighting against Memnon Leide...   \n",
       "\n",
       "                                            outlinks  \\\n",
       "0  [Anti-authoritarianism, political philosophy, ...   \n",
       "1  [Psychiatry, Interpersonal relationship, commu...   \n",
       "2  [File:Albedo-e hg.svg, diffuse reflection, sun...   \n",
       "3  [Coat of arms of Alabama, Northern flicker, Di...   \n",
       "4  [File:Achilles fighting against Memnon Leiden ...   \n",
       "\n",
       "                                     tokens_lem_stem  \n",
       "0  [anarch, anti, authoritarian, anti, authoritar...  \n",
       "1  [autism, development, disord, character, diffi...  \n",
       "2  [sunlight, relat, various, surfac, condit, alb...  \n",
       "3  [alabama, alabama, nicknam, northern, flicker,...  \n",
       "4  [date, three, zero, zero, bc, achill, kill, et...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:guidedlda:all zero row in document-term matrix found\n",
      "/home/nh1724/.conda/envs/lda/lib/python3.6/site-packages/guidedlda/utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n"
     ]
    }
   ],
   "source": [
    "#document topics assignment\n",
    "doc_topic = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(doc_topic, open(PATH_TO_DATA + \"features_top.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def get_metrics_dict(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset.\n",
    "    \"\"\"\n",
    "    # macro precision, recall, f-score\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average=\"macro\"\n",
    "    )\n",
    "    # micro precision, recall, f-score\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average=\"micro\"\n",
    "    )\n",
    "    # combine all metrics in a dict\n",
    "    dict_metrics = {\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"precision_micro\": precision_micro, \n",
    "        \"recall_micro\": recall_micro, \n",
    "        \"f1_micro\": f1_micro,\n",
    "    }\n",
    "    # round\n",
    "    n_digits = 3\n",
    "    dict_metrics = {\n",
    "        metric_name: round(value, n_digits) \n",
    "        for metric_name, value in dict_metrics.items()\n",
    "    }\n",
    "    return dict_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold: each doc topic sum to 1, threshold topic w/ prob > 1/45\n",
    "from copy import deepcopy\n",
    "y_pred = deepcopy(doc_topic)\n",
    "y_pred = np.where(y_pred>1/45, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics_dict(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get X_test sparse input\n",
    "bow_corpus_test = [dictionary.doc2bow(doc) for doc in X_test.tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:guidedlda:all zero row in document-term matrix found\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2, 23549), indices imply (3383, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1677\u001b[0m                 blocks = [\n\u001b[0;32m-> 1678\u001b[0;31m                     \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1679\u001b[0m                 ]\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   3283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3284\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;34m\"Wrong number of items passed {val}, placement implies \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0;34m\"{mgr}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 23549, placement implies 7",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-d762dc2dfa8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_topic_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#model.transform(X_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/guidedlda/guidedlda.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, max_iter, tol)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mdoc_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mWS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguidedlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_to_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;31m# TODO: this loop is parallelizable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/guidedlda/utils.py\u001b[0m in \u001b[0;36mmatrix_to_lists\u001b[0;34m(doc_word)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected sparse matrix with integer values, found float values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m     \"\"\"\n\u001b[0;32m-> 1849\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nonzero'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   1997\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_axes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1999\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m     \u001b[0;31m# ideally we would define this to avoid the getattr checks, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lda/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1717\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0;34m\"Shape of passed values is {0}, indices imply {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m     )\n\u001b[1;32m   1721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (2, 23549), indices imply (3383, 7)"
     ]
    }
   ],
   "source": [
    "doc_topic_test = model.transform(X_test) #model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse input of X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save test features first\n",
    "pkl.dump(doc_topic_test, open(PATH_TO_DATA + \"features_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(dictionary.values()) #list of terms in the dictionary\n",
    "vocab_tf = [dict(i) for i in bow_corpus]\n",
    "vocab_tf = list(pd.DataFrame(vocab_tf).sum(axis=0)) #list of term frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results for visz:https://github.com/vi3k6i5/GuidedLDA/issues/23\n",
    "visz = {'topic_term_dists':topic_word,\n",
    "        'doc_topic_dists':doc_topic,\n",
    "        'doc_lengths': doc_lengths,\n",
    "        'vocab':vocab, \n",
    "        'term_frequency':vocab_tf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(visz,open(PATH_TO_DATA + \"visz.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import visz data\n",
    "data = pkl.load(open(PATH_TO_DATA + \"visz.pkl\", \"rb\"))\n",
    "import pyLDAvis\n",
    "# prepare the data\n",
    "tef_vis_data = pyLDAvis.prepare(**data)\n",
    "\n",
    "# this bit needs to be run after running the earlier code for reasons\n",
    "pyLDAvis.display(tef_vis_data)\n",
    "\n",
    "# save to HTML\n",
    "pyLDAvis.save_html(tef_vis_data, \"LDAvis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick check of results\n",
    "for i in range(5): \n",
    "    print(\"Top Topic: {}; True Topic {}; Document: {}\".format(doc_topic[i].argsort()[-5:][::-1],\n",
    "                                                              np.where(y_train[i]==1)[0].tolist(),\n",
    "                                                              ', '.join([dictionary.id2token[t] for t in np.argsort(X_train[i].toarray().flatten())[:-6:-1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "doc_topic_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output feature vectors of doc-topic distribution for graphical NN usage\n",
    "pkl.dump(np.concatenate((doc_topic,doc_topic_test),axis=0), open(PATH_TO_DATA + \"features.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %install_ext https://raw.github.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "# %load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA with eta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nh1724/.conda/envs/lda/lib/python3.6/site-packages/gensim/models/ldamodel.py:1108: RuntimeWarning: invalid value encountered in multiply\n",
      "  score += np.sum((self.eta - _lambda) * Elogbeta)\n",
      "/home/nh1724/.conda/envs/lda/lib/python3.6/site-packages/gensim/models/ldamodel.py:1109: RuntimeWarning: invalid value encountered in subtract\n",
      "  score += np.sum(gammaln(_lambda) - gammaln(self.eta))\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "lda = models.LdaMulticore(bow_corpus, num_topics=45, id2word=dictionary, passes=2, workers=4, eta=eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/nh1724'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Save model to disk.\n",
    "temp_file = datapath(\"model\")\n",
    "#lda.save(temp_file)\n",
    "pkl.dump(temp_file, open(PATH_TO_DATA + \"base_model_eta.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarch', 'anti', 'authoritarian', 'anti', 'authoritarian', 'polit', 'philosophi', 'anarch', 'usual', 'place'] ['(4, 84.0%)', '(17, 6.7%)', '(20, 2.7%)', '(33, 6.2%)']\n",
      "['autism', 'development', 'disord', 'character', 'difficulti', 'social', 'interact', 'communic', 'restrict', 'repetit'] ['(28, 58.1%)', '(33, 41.8%)']\n",
      "['sunlight', 'relat', 'various', 'surfac', 'condit', 'albedo', 'mean', 'whiten', 'measur', 'diffus'] ['(0, 61.6%)', '(2, 31.8%)', '(7, 5.4%)', '(34, 1.1%)']\n",
      "['alabama', 'alabama', 'nicknam', 'northern', 'flicker', 'yellowhamm', 'state', 'list', 'state', 'bird'] ['(4, 1.4%)', '(9, 15.6%)', '(12, 11.4%)', '(20, 12.6%)', '(23, 19.8%)', '(40, 26.4%)', '(41, 12.8%)']\n",
      "['date', 'three', 'zero', 'zero', 'bc', 'achill', 'kill', 'ethiopian', 'king', 'memnon'] ['(3, 54.7%)', '(22, 8.2%)', '(42, 36.7%)']\n"
     ]
    }
   ],
   "source": [
    "for line,bag in zip(wiki_df.tokens[:5],bow_corpus[:5]):\n",
    "    doc_topics = ['({}, {:.1%})'.format(topic, prob) for topic,prob in lda.get_document_topics(bag)]\n",
    "    print('{} {}'.format(line[0:10], doc_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_set = set(wiki_df.title)\n",
    "title_lower_set = set(wiki_df.title.apply(lambda x: x.lower()))\n",
    "len(titles_set), len(title_lower_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_with_lowercase_titles(links_list):\n",
    "    count = 0\n",
    "    for link in links_list:\n",
    "        if link.lower() in title_lower_set:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def overlap_with_titles(links_list):\n",
    "    count = 0\n",
    "    for link in links_list:\n",
    "        if link in titles_set:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "wiki_df[\"links_cleaned\"] = wiki_df.links.apply(clean_links)\n",
    "wiki_df[\"count_overlap\"] = wiki_df.links_cleaned.apply(overlap_with_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.median(wiki_df.count_overlap), np.mean(wiki_df.count_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(wiki_df.count_overlap == 0).sum() / len(wiki_df.count_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median, mean = np.median(wiki_df.count_overlap), np.mean(wiki_df.count_overlap)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(wiki_df.count_overlap, bins=150)\n",
    "y_lim = 6e3\n",
    "plt.vlines(median, 0, y_lim, colors=\"orange\", linestyles='--', label=f\"Median {median}\")\n",
    "plt.vlines(mean, 0, y_lim, colors=\"orange\", linestyles='solid', label=f\"Mean {mean:.3}\")\n",
    "plt.xlim(0, 300)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of outlinks\")\n",
    "plt.title(\"Distribution of outlinks within the graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(wiki_df.mid_level_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb.transform([['Culture.Architecture', 'Culture.Arts', 'Culture.Broadcasting']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df.mid_level_categories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df.links_cleaned[:9].apply(overlap_with_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wiki_df.links[:5].apply(clean_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df.links = wiki_df.links.apply(links_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lda",
   "language": "python",
   "name": "lda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
